# 实验记录



以MINDsmall_train为例

## News Encdoer

### 抽取新闻特征

news_title.tsv先用bert来抽取新闻标题得到词向量。

使用transformers库来做，选择官方提供的12层的transformer。

每一层transformer的输出值，理论上来说都可以作为句向量，但是到底应该取哪一层呢，根据hanxiao大神的实验数据，最佳结果是取倒数第二层，最后一层的值太接近于目标，前面几层的值可能语义还未充分的学习到。

以“After stealing money from the **bank vault**, the **bank robber** was seen fishing on the Mississippi **river bank**.”作为输入来比较：

将最后四层叠加：

![截屏2020-12-07 下午9.01.28](https://i.loli.net/2020/12/07/X6EQL7pnuVemJ9c.png)

拼接最后四层：

![截屏2020-12-07 下午9.04.23](https://i.loli.net/2020/12/07/5ZfM1cGNpLbesq4.png)

取倒数第二层：

![截屏2020-12-07 下午9.05.40](https://i.loli.net/2020/12/07/MeIkoNuVGB5JzRh.png)

取最后一层：

![截屏2020-12-07 下午9.06.25](https://i.loli.net/2020/12/07/RlnaBY7NLvx8PU3.png)

取倒数第三层：

![截屏2020-12-07 下午9.14.11](https://i.loli.net/2020/12/07/13z4Gyi726FaxeK.png)

最终效果应该取决于任务，最后再微调。



### 计算外部特征

behaviors.tsv里面为一个印象日志，包括一个用户的点击历史和该用户的点击行为

外部特征应该只考虑点击历史里面的新闻。

以新闻为行，用户为列，构建一条新闻是否被用户点击的one-hot向量组成一个矩阵。

新闻和用户都约5万条，高维稀疏矩阵逐个向量进行关系计算或比较。



先构建矩阵，保存。

由于维度高、数据规模大，直接应用最近邻方法并不可行，因此，最佳实践是使用逼近方法搜索最近邻，使用比较常见的Annoy来实践。

一般的问题是任意一个向量与其最邻近的向量是哪些，但此处我们想要根据向量之间的关系特征来进行查找，而不是内容特征，因此此处相当于自己重新构建一个数据集，所以一定的工作时间和资源要求必不可少



查找最近邻流程：

​	初始化全为0的大矩阵

​	遍历用户点击记录修改矩阵每列的值，得到经过修改的大矩阵，矩阵约76G

​	以行遍历大矩阵加入annoy的子节点，创建存储索引树

​	遍历新闻为每篇新闻选取k个最近邻，存储起来





使用annoy保存50000x50000的矩阵组成的索引需要大概10G，但加载时十分迅速，不到一秒。

待做：测试其它库占用空间和内存。如faiss







## User Encdoer





baseline 实验：

NPA

all

evaluation results:{'group_auc': 0.6427, 'ndcg@5': 0.323, 'ndcg@10': 0.388, 'mean_mrr': 0.2949}

只对新闻的文本抽取器进行测试

测试样本为100、500、1000、2000、3000、全部

（1）news-Encoder只使用glove词嵌入+CNN，user-Encoder拼凑点击新闻向量

evaluation results:{'group_auc': 0.6771, 'ndcg@5': 0.2493, 'ndcg@10': 0.3316, 'mean_mrr': 0.2527}

evaluation results:{'group_auc': 0.6197, 'ndcg@5': 0.3169, 'ndcg@10': 0.3725, 'mean_mrr': 0.2821}

evaluation results:{'group_auc': 0.6296, 'ndcg@5': 0.3126, 'ndcg@10': 0.3773, 'mean_mrr': 0.2859}

evaluation results:{'group_auc': 0.6394, 'ndcg@5': 0.3142, 'ndcg@10': 0.3784, 'mean_mrr': 0.2872}

evaluation results:{'group_auc': 0.6348, 'ndcg@5': 0.315, 'ndcg@10': 0.3786, 'mean_mrr': 0.2874}

evaluation results:{'group_auc': 0.6329, 'ndcg@5': 0.3168, 'ndcg@10': 0.3809, 'mean_mrr': 0.2886}

（2）使用论文所说的CNN+maxpooling，参数任意选，未调

evaluation results:{'group_auc': 0.7069, 'ndcg@5': 0.2688, 'ndcg@10': 0.3533, 'mean_mrr': 0.273}

evaluation results:{'group_auc': 0.633, 'ndcg@5': 0.3231, 'ndcg@10': 0.381, 'mean_mrr': 0.2902}

evaluation results:{'group_auc': 0.6252, 'ndcg@5': 0.3137, 'ndcg@10': 0.3736, 'mean_mrr': 0.2857}

evaluation results:{'group_auc': 0.6498, 'ndcg@5': 0.3161, 'ndcg@10': 0.3848, 'mean_mrr': 0.2945}

evaluation results:{'group_auc': 0.6388, 'ndcg@5': 0.3197, 'ndcg@10': 0.3824, 'mean_mrr': 0.2942}

evaluation results:{'group_auc': 0.6358, 'ndcg@5': 0.3167, 'ndcg@10': 0.3817, 'mean_mrr': 0.2919}

（3）使用pyotrch提供的transformerEncoder来抽取新闻文本特征

 evaluation results:{'group_auc': 0.5224, 'ndcg@5': 0.1838, 'ndcg@10': 0.2345, 'mean_mrr': 0.1832, 'acc': 0.0814}

evaluation results:{'group_auc': 0.5117, 'ndcg@5': 0.2328, 'ndcg@10': 0.2941, 'mean_mrr': 0.2215, 'acc': 0.1142}

evaluation results:{'group_auc': 0.4962, 'ndcg@5': 0.2263, 'ndcg@10': 0.2858, 'mean_mrr': 0.2193, 'acc': 0.1066}



目前效果不好，一方面没跑完10个epoch，一个epoch30分钟有点久，也可能用法有问题。

修改：transformer加入位置编码，用100个batch调试：

evaluation results:{'group_auc': 0.5233, 'ndcg@5': 0.186, 'ndcg@10': 0.2389, 'mean_mrr': 0.1756, 'acc': 0.9268}

evaluation results:{'group_auc': 0.5221, 'ndcg@5': 0.2507, 'ndcg@10': 0.3127, 'mean_mrr': 0.2397, 'acc': 0.8954}

evaluation results:{'group_auc': 0.5419, 'ndcg@5': 0.2484, 'ndcg@10': 0.3181, 'mean_mrr': 0.2338, 'acc': 0.901}

evaluation results:{'group_auc': 0.5508, 'ndcg@5': 0.2481, 'ndcg@10': 0.3115, 'mean_mrr': 0.2309, 'acc': 0.9046}

evaluation results:{'group_auc': 0.5392, 'ndcg@5': 0.2512, 'ndcg@10': 0.314, 'mean_mrr': 0.2377, 'acc': 0.8988}

对比CNN用100个batchtransformer效果完全垃圾，应该是用法有问题，但其acc极高

evaluation results:{'group_auc': 0.6064, 'ndcg@5': 0.2204, 'ndcg@10': 0.2893, 'mean_mrr': 0.2237, 'acc': 0.0734}

evaluation results:{'group_auc': 0.5894, 'ndcg@5': 0.2886, 'ndcg@10': 0.3473, 'mean_mrr': 0.2638, 'acc': 0.1046}

evaluation results:{'group_auc': 0.5719, 'ndcg@5': 0.2697, 'ndcg@10': 0.3298, 'mean_mrr': 0.2513, 'acc': 0.0991}

调整损失函数，transformer加入位置编码，用50个batch训练（GPU限制）：

evaluation results:{'group_auc': 0.5581, 'ndcg@5': 0.1779, 'ndcg@10': 0.2528, 'mean_mrr': 0.1907, 'acc': 0.9268}

evaluation results:{'group_auc': 0.564, 'ndcg@5': 0.2729, 'ndcg@10': 0.3428, 'mean_mrr': 0.2588, 'acc': 0.8954}

evaluation results:{'group_auc': 0.5577, 'ndcg@5': 0.2634, 'ndcg@10': 0.3282, 'mean_mrr': 0.2512, 'acc': 0.901}

evaluation results:{'group_auc': 0.5654, 'ndcg@5': 0.2561, 'ndcg@10': 0.3236, 'mean_mrr': 0.2437, 'acc': 0.9046}

看到性能逐渐提高，但loss下降比较少，考虑损失下降的问题，加大epoch数效果还是不好

evaluation results:{'group_auc': 0.5698, 'ndcg@5': 0.2083, 'ndcg@10': 0.2672, 'mean_mrr': 0.1993, 'acc': 0.9268}

evaluation results:{'group_auc': 0.5258, 'ndcg@5': 0.2481, 'ndcg@10': 0.3051, 'mean_mrr': 0.2329, 'acc': 0.8954}

evaluation results:{'group_auc': 0.5292, 'ndcg@5': 0.2372, 'ndcg@10': 0.2954, 'mean_mrr': 0.2197, 'acc': 0.901}

evaluation results:{'group_auc': 0.5468, 'ndcg@5': 0.238, 'ndcg@10': 0.3036, 'mean_mrr': 0.2274, 'acc': 0.9046}

（4）改为只使用1头自注意力，效果明显比拟CNN，但未明显超越，100个batch

evaluation results:{'group_auc': 0.5986, 'ndcg@5': 0.2171, 'ndcg@10': 0.2752, 'mean_mrr': 0.2126, 'acc': 0.9266}

evaluation results:{'group_auc': 0.5642, 'ndcg@5': 0.2757, 'ndcg@10': 0.347, 'mean_mrr': 0.2684, 'acc': 0.8954}

evaluation results:{'group_auc': 0.5671, 'ndcg@5': 0.2569, 'ndcg@10': 0.325, 'mean_mrr': 0.2485, 'acc': 0.9009}

evaluation results:{'group_auc': 0.582, 'ndcg@5': 0.2603, 'ndcg@10': 0.3289, 'mean_mrr': 0.2488, 'acc': 0.9046}

evaluation results:{'group_auc': 0.5672, 'ndcg@5': 0.2672, 'ndcg@10': 0.3346, 'mean_mrr': 0.2568, 'acc': 0.8988}

加大参数，3头，heads必须为维度300整除：

evaluation results:{'group_auc': 0.6138, 'ndcg@5': 0.231, 'ndcg@10': 0.3066, 'mean_mrr': 0.2397, 'acc': 0.9266}

evaluation results:{'group_auc': 0.5634, 'ndcg@5': 0.2682, 'ndcg@10': 0.3375, 'mean_mrr': 0.2527, 'acc': 0.8954}

evaluation results:{'group_auc': 0.5587, 'ndcg@5': 0.2547, 'ndcg@10': 0.3282, 'mean_mrr': 0.2445, 'acc': 0.9009}

evaluation results:{'group_auc': 0.5703, 'ndcg@5': 0.2514, 'ndcg@10': 0.32, 'mean_mrr': 0.2392, 'acc': 0.9046}

evaluation results:{'group_auc': 0.565, 'ndcg@5': 0.2649, 'ndcg@10': 0.3328, 'mean_mrr': 0.2516, 'acc': 0.8988}

6头：

evaluation results:{'group_auc': 0.6003, 'ndcg@5': 0.2142, 'ndcg@10': 0.2747, 'mean_mrr': 0.2088, 'acc': 0.1431}

evaluation results:{'group_auc': 0.5416, 'ndcg@5': 0.2486, 'ndcg@10': 0.3184, 'mean_mrr': 0.2346, 'acc': 0.1724}

evaluation results:{'group_auc': 0.5422, 'ndcg@5': 0.2375, 'ndcg@10': 0.3052, 'mean_mrr': 0.2242, 'acc': 0.1671}

evaluation results:{'group_auc': 0.5634, 'ndcg@5': 0.241, 'ndcg@10': 0.3104, 'mean_mrr': 0.2297, 'acc': 0.1629}

evaluation results:{'group_auc': 0.549, 'ndcg@5': 0.2479, 'ndcg@10': 0.3176, 'mean_mrr': 0.2362, 'acc': 0.1678}

还是只取1头自注意力，全部数据训练，还是比不上CNN

evaluation results:{'group_auc': 0.5988, 'ndcg@5': 0.2309, 'ndcg@10': 0.2903, 'mean_mrr': 0.2304, 'acc': 0.1134}

evaluation results:{'group_auc': 0.5609, 'ndcg@5': 0.2711, 'ndcg@10': 0.3366, 'mean_mrr': 0.2497, 'acc': 0.1416}

evaluation results:{'group_auc': 0.5448, 'ndcg@5': 0.2462, 'ndcg@10': 0.3152, 'mean_mrr': 0.2332, 'acc': 0.1357}

evaluation results:{'group_auc': 0.5665, 'ndcg@5': 0.2686, 'ndcg@10': 0.3255, 'mean_mrr': 0.2503, 'acc': 0.1308}

evaluation results:{'group_auc': 0.5626, 'ndcg@5': 0.2659, 'ndcg@10': 0.3276, 'mean_mrr': 0.2488, 'acc': 0.1378}

（5）还是用trasnformer，全部数据，跑20个epoch，batch=64，使用head=15

evaluation results:{'group_auc': 0.6453, 'ndcg@5': 0.2721, 'ndcg@10': 0.3217, 'mean_mrr': 0.2531, 'acc': 0.9268}

evaluation results:{'group_auc': 0.6226, 'ndcg@5': 0.3264, 'ndcg@10': 0.3866, 'mean_mrr': 0.2927, 'acc': 0.8954}

evaluation results:{'group_auc': 0.6158, 'ndcg@5': 0.305, 'ndcg@10': 0.3635, 'mean_mrr': 0.2775, 'acc': 0.901}

evaluation results:{'group_auc': 0.6115, 'ndcg@5': 0.2892, 'ndcg@10': 0.3549, 'mean_mrr': 0.2643, 'acc': 0.9045}

evaluation results:{'group_auc': 0.6086, 'ndcg@5': 0.3021, 'ndcg@10': 0.3635, 'mean_mrr': 0.2795, 'acc': 0.8988}

evaluation results:{'group_auc': 0.6108, 'ndcg@5': 0.3038, 'ndcg@10': 0.3646, 'mean_mrr': 0.2762, 'acc': 0.8999}

调节后效果提高但比CNN还是差点，loss下降还是比较少，故训练50个epoch

（6）单独使用Glove词嵌入：

evaluation results:{'group_auc': 0.5568, 'ndcg@5': 0.2001, 'ndcg@10': 0.2544, 'mean_mrr': 0.1918, 'acc': 0.0874}

evaluation results:{'group_auc': 0.5233, 'ndcg@5': 0.2585, 'ndcg@10': 0.315, 'mean_mrr': 0.2423, 'acc': 0.1199}

evaluation results:{'group_auc': 0.5247, 'ndcg@5': 0.2497, 'ndcg@10': 0.3103, 'mean_mrr': 0.2356, 'acc': 0.1184}

evaluation results:{'group_auc': 0.5245, 'ndcg@5': 0.2295, 'ndcg@10': 0.2958, 'mean_mrr': 0.2214, 'acc': 0.1139}

evaluation results:{'group_auc': 0.5212, 'ndcg@5': 0.2438, 'ndcg@10': 0.3085, 'mean_mrr': 0.2347, 'acc': 0.1198}

evaluation results:{'group_auc': 0.5239, 'ndcg@5': 0.2422, 'ndcg@10': 0.3067, 'mean_mrr': 0.2326, 'acc': 0.1188}

(7)使用CNN+MaxPooling作为news encoder,使用最简单的GCN作为user encoder（只汇聚用户节点的邻居节点）：

（8）看了GCMC，尝试把新闻推荐直接当成一个矩阵补全问题来做，效果很差，movielen的矩阵补全问题核心是一个多分类问题，新闻推荐的问题是点击率预测问题，虽然把它看作一个二分类问题，但直接用印象日志的样本做的话会导致负样本即分类为0的样本远远大于正样本，即使使用负采样技术也会导致负样本远多于正样本，若取一个正样本和负样本又失去了图的作用，因此邻居节点只有两个。因此图自编码器不能应用于印象日志上。

若将GAE应用在点击历史上，则等价于图自编码器接下游任务，一方面是GAE一般用整个图进行运算，内存占用过大，且不好处理下游任务的批数据。即使把图拆开计算，最后还是需要重组图的领接矩阵来进行差异的比较损失。

因此新闻推荐的一个问题是数据量过大，用增量可以避免一个数据量过大的问题。

但基于增量学习的新闻推荐又会出现问题：
（1）如何切分数据集，首先是如何切分训练集，按数量切分极端可能会导致子集数据分布一致，即域是不变的，按用户划分更加合理，但数据量不一致。然后是测试集的问题，增量问题一般是每个任务都有对应的训练集和 测试机，在加入新的任务后才可以和其他方法比较它的灾难性遗忘程度。但新闻推荐的训练集和测试集是分离，并没有部分的训练集和测试集是对应的，难以为每个任务划分对应的测试集。

（2）新闻推荐实质是点击率预测问题，是伪分类问题，增量学习一般针对于分类问题，很多baseline没办法直接使用，比如LwF，分类问题一般最后接softmax输出概率分布，但新闻推荐的最后是点积，好像没办法使用旧任务的输出作为新任务的软标签。还有基于replay的方法，如何选择具有代表性的样本。

（3）一般方法是replay、正则化项或知识蒸馏的方法、参数隔离方法，三个方向选择哪个方向下手





参考：

【1】https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#23-segment-id

【2】https://zhuanlan.zhihu.com/p/50604120