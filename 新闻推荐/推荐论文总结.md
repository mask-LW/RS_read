基于GNN的新闻推荐

1⃣️Graph Enhanced Representation Learning for News Recommendation

考虑相邻新闻对候选新闻的影响以及相邻用户对当前用户对影响，通过图注意力网络聚合用户和新闻的邻居嵌入，加强用户和新闻的特征表示
使用简化的transformer，原版性能次优，抽取文本特征

attention得到用户表示、嵌入表示用户ID

图+邻居节点attention：利用邻居新闻得到新闻表示、利用邻居ID得到用户ID表示、利用新闻ID得到新闻ID表示

GAT思路

2⃣️Gaph Neural News Recommendation with Long-term and Short-term Interest Modeling

使用图神经网络得到用户的长期兴趣和新闻的表征，LSTM+attention得到用户的短期兴趣

最简单的聚合邻居节点的特征然后做一个线性变换

GCN思路

3⃣️Graph Neural News Recommendation with Unsupervised Preference Disentanglement

将用户-新闻交互建模为二部图，通过无监督偏好解构，分离用户偏好到不同的偏好空间。

图神经网络聚合过程结合分离式表征计算邻居节点

4⃣️KIM：Personalized News Recommendation with Knowledge-aware Interactive Matching

通过co-encoder编码新闻之间的实体交互，用户和新闻的交互，图+cross-attention



4⃣️MVL

以一般的NPA模型得到图卷积的输入，然后分层进行基于注意力的图卷积，通过用户-新闻-用户、新闻-用户-新闻分别进行两次GAT。以用户为例，要想计算用户，需要先用GAT计算其每个邻居新闻，再对其每个邻居新闻使用GAT



结合知识图谱：

1⃣️DKN

2⃣️





NPA（2019）：针对新闻级和单词级的个性化注意力

LSTUR（2019）：GRU捕获短期兴趣，ID嵌入作为长期兴趣

NAML（2019）：

NRMS（2019）：应用多头自注意力捕捉长距离的单词交互;

DKN（2018）：通过知识图谱引入外部知识





NGCF：将user-item之间的协同信息建模到user和item的emebdding表示，同样是捕获邻居节点，但考虑自身以及自身同邻居节点的交互信息















创新点：
1⃣️潜在偏好：图做相似度处理得到用户的相似节点

2⃣️用户表示

3⃣️新闻表示

4⃣️潜在偏好：用户往往有难以从历史交互记录提取的潜质偏好，一方面是随机偏好，可能会由突发事件而导致，比如突然患了某个疾病活着发生了什么重大事件，这部分是没法得知的偏好，因此只能用一个随机初始化的向量来进行表示；另一方面是由可能存在的来源导致的偏好，主要来源于相似用户B的交互记录中未发生在当前用户A的交互记录的item，因为相似用户的偏好极其相似，那么用户B的交互记录都可能存在A的交互记录中，那么目前不存在A的交互记录中的item就可能是A的偏好

5⃣️受NGCF论文启发，user和item的交互记录中是存在重要的协同信息的，但传统的GCN一般是聚合邻居节点进行整合而未考虑协同信息，那么在新闻推荐应用GCN时就可以考虑不仅聚合邻居节点，还聚合其中的协同信息，NGCF是采取所有节点一起计算协同信息来加快计算速度，但原来的打算是为了减少内存，每次只对邻居节点进行处理。

6⃣️延续胶囊网络的想法，通过GCN生成多个子图代表用户偏好实现聚类效果。

用k个图编码器得到k个子图







套用思路

1⃣️由于用户的点击历史是序列数据，所以可以在应用GCN时使用LSTM的方法来聚合邻居用户（即用户的点击新闻序列）

目前没有人做过

2⃣️使用对比学习的triple loss来代替原本的损失函数，待测试，但该方法比较麻烦，目前估计需要重新处理数据的输入和损失计算，代码需要重写

