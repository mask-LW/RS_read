



# Personalized News Recommendation with Knowledge-aware Interactive Matching

Tao Qi 1, Fangzhao Wu2 , Chuhan Wu1 , Yongfeng Huang1

1Department of Electronic Engineering & BNRist, Tsinghua University, Beijing 100084

 2Microsoft Research Asia, Beijing 100080, China 



SIGIR2021



# 前言

![截屏2021-05-15 下午9.32.44](https://i.loli.net/2021/05/15/EruXSC2HjehqG5o.png)

候选新闻文章可能包含多个方面和实体，用户可能有多个兴趣爱好[33]。因此，对于兴趣匹配[32]，候选新闻和用户兴趣的独立建模可能较差。

首先，候选新闻可能涵盖不同的方面和实体，用户可能有多种兴趣。例如，图1中的候选新闻与一部电影和一家技术公司有关，涵盖了几个实体，如“movie Cats”和“Netflix”

此外，图1中的示例用户对不同的领域感兴趣，如政治、体育和娱乐。

另外，我们可以发现候选新闻只能匹配特定的用户兴趣，即娱乐，而用户兴趣只能匹配特定的候选新闻方面，即电影。

因此，

如果候选新闻是独立建模的，那么将用户兴趣与候选新闻进行匹配是较差的。

其次，用户兴趣与候选新闻的匹配通常隐含在被点击新闻文本与候选新闻文本的匹配中。例如，我们可以从被点击新闻中的文本“trending song”和候选新闻中的“popular movie”之间的语义关联来推断用户可能对候选新闻感兴趣，因为它们都是热门作品。

第三，借助知识图谱，将被点击新闻中的实体与候选新闻中的实体进行匹配，有助于理解用户对候选新闻的兴趣。

例如,我们可以在点击新闻找到实体“Song style”和候选新闻的实体“Movie Cats”存在内在联系，因为前者是泰勒的歌，后者电影的女主角也是泰勒,由此我们可以推断用户可能感兴趣

因此，在文本和实体层面上有效地挖掘被点击新闻与候选新闻之间的相关性有利于兴趣匹配。

具体工作：

1⃣️knowledge co-encoder即graph co-attention network通过选择和聚集实体的邻居来学习知识图中的实体表示，这些邻居为兴趣匹配提供了信息

2⃣️text co-encoder交互学习基于文本表示的用户点击新闻和候选新闻之间的语义关联建模。

# METHODOLOGY

![截屏2021-05-15 下午9.41.35](https://i.loli.net/2021/05/15/sLY1eHqDz5of2EN.png)

### Knowledge-aware News Co-Encoder

![截屏2021-05-15 下午9.47.19](https://i.loli.net/2021/05/15/RwobeN5z8mUITty.png)

基于知识图谱对点击新闻𝑛𝑢和候选新闻𝑛𝑐基于知识的表示k𝑢和k𝑐进行交互学习

![截屏2021-05-15 下午9.49.00](https://i.loli.net/2021/05/15/ZScRt8ANzpFOhWi.png)

$k^u和k^c \in R_{d_k},d_k表示基于知识的新闻表征的维度，E^u和E^c表示点击新闻和候选新闻的实体$

对新闻𝑛𝑢和𝑛𝑐交互学习基于文本的表示t𝑢和t𝑐，从候选新闻的文本之间的语义关联建模用户对它们的兴趣:

![截屏2021-05-15 下午9.53.33](https://i.loli.net/2021/05/15/TNjFynOQJCqvUG5.png)

$t^u和t^c \in R_{d_t},d_t表示基于文本的新闻表征的维度，T^u和T^c表示点击新闻和候选新闻的文本$

最后，我们将同一新闻的知识表示和文本表示投射到统一的新闻表示中:

![截屏2021-05-15 下午9.55.26](https://i.loli.net/2021/05/15/eVPbDO6sJq2Glfv.png)

$n^u和\in R_{d_n},d_n表示点击新闻基于知识感知的表征，n^c和\in R_{d_n},d_n表示候选新闻基于知识感知的表征$

### knowledge co-encoder 

知识协同编码器，该编码器可以交互学习用户点击新闻𝑛𝑢和候选新闻𝑛𝑐的知识表示

通过知识图G更好地表示新闻，以便用户点击新闻和候选新闻中实体之间的相关性进行兴趣匹配，得到新闻基于知识的表征

![截屏2021-05-15 下午9.59.59](https://i.loli.net/2021/05/15/MFatdRDJehkTclf.png)

1⃣️GAT

通过K层的graph attention (GAT) network汇总邻居节点的实体信息T分别得到用户点击新闻和候选新闻的的表示M

2⃣️stacked graph co-attention network （GCAT）

为了更好地选择实体之间的信息关联来匹配具有用户兴趣的候选新闻，我们提出了一个基于𝐾层的图共同关注网络(GCAT)来学习新闻𝑛𝑢和𝑛𝑐中的实体的匹配感知表示。

![截屏2021-05-15 下午10.31.39](https://i.loli.net/2021/05/15/j2dmEa5YK6Zx4WP.png)

一个实体通常与知识图上的不同实体具有丰富的相关性。

实体间的相关度通常提供不同的信息量来建模被点击新闻与候选新闻之间的相关度以进行兴趣匹配。

因此两个新闻的实体可能通过一个邻居相连，该实体给予新闻的建模信息更加重要



以新闻𝑛𝑢中的实体𝑒为例，图4所示的𝑙-th图共同关注网络通过聚合新闻𝑛𝑐中的实体指导，聚合𝑛𝑢邻居的表示来学习其表示。

更具体地说，我们首先将一个多头自注意网络应用于由(𝑙−1)-th GCAT网络生成的邻居实体表示，以建模不同邻居实体之间的概念关联。

然后，我们提出了一个匹配感知的注意网络，基于实体𝑒的邻居实体与新闻𝑛𝑐中的实体的相关性来聚合该实体：

![截屏2021-05-15 下午10.39.01](https://i.loli.net/2021/05/15/yUta83SBOY4NCwn.png)

![截屏2021-05-17 上午11.19.25](https://i.loli.net/2021/05/17/Vx1Pzim43qUIHlr.png)

然后计算聚合得到g

![截屏2021-05-17 上午11.19.35](https://i.loli.net/2021/05/17/o7QjDWAhTkl3N8y.png)

简单来说就是用户点击历史的新闻u的实体e通过聚合其邻居节点，再和候选新闻c的实体做一个注意力匹配。

3⃣️entity co-attention network

应用实体共同关注网络，通过获取新闻𝑛𝑢和𝑛𝑐实体之间的相关性，交互学习基于知识的表示。

主要通过计算点击新闻和候选新闻实体的相关性，然后分别计算各自的表示

![截屏2021-05-17 上午11.19.54](https://i.loli.net/2021/05/17/e9BUX4CqhPfJGKS.png)

![截屏2021-05-17 上午11.20.02](https://i.loli.net/2021/05/17/GjyI6xE4Nw95qlF.png)



![截屏2021-05-17 上午11.20.24](https://i.loli.net/2021/05/17/zrLH3cSgh1Ej9s6.png)



### Text Co-Encoder

![截屏2021-05-15 下午10.46.46](https://i.loli.net/2021/05/15/PlLARqK98oiGy2E.png)



文本协编码器交互学习用户点击新闻𝑛𝑢和候选人新闻𝑛𝑐的基于文本的表示。它的目的是通过候选新闻的文本之间的相关性(𝑇𝑢和𝑇𝑐)更好地模拟用户对候选新闻的兴趣。

首先学习新闻的嵌入表示，然后通过CNN和transformer得到局部的上下文表示Lu和全局的上下文表示Ju，聚合得到Hu和Hc（分别）。

最后计算点击新闻和候选新闻的不同词之间的语义相关性，得到注意力权重聚合表示，得到用户新闻和候选新闻的文本表示

![截屏2021-05-17 上午11.16.33](https://i.loli.net/2021/05/17/WrdoyhSeUOTqlNC.png)

![截屏2021-05-17 上午11.16.52](https://i.loli.net/2021/05/17/q6cSnWfG8eLOuDR.png)

![截屏2021-05-17 上午11.17.01](https://i.loli.net/2021/05/17/zbpNWYRXPSQnhlv.png)





### User-Candidate Co-Encoder

学习 候选新闻感知 的用户兴趣表征 和  用户感知的候选新闻表征

首先计算用户点击新闻和候选新闻的相关性，然后分别计算注意力权重，然后聚合得到特征表示

$点击新闻N_u = (n^u_i)^N_{i=1},N为新闻数量，候选新闻N_c = (n^c_i)^N_{i=1},二者都为R^{{d_k}*N}$

相关性计算：

![截屏2021-05-17 上午11.14.08](https://i.loli.net/2021/05/17/akeJ1ZH9sUmhVc7.png)

分别计算注意力权重：

![截屏2021-05-17 上午11.14.20](https://i.loli.net/2021/05/17/KO3AamG9l8ciNzx.png)

注意，此处的权重计算每个都包含点击新闻和候选新闻，相互感知

聚合表征：

![截屏2021-05-17 上午11.15.04](https://i.loli.net/2021/05/17/r6u8UEkX32cY4mO.png)



# 实验

![截屏2021-05-17 上午11.26.43](https://i.loli.net/2021/05/17/ngBVJYSuvHeN3PT.png)



![截屏2021-05-17 上午11.22.07](https://i.loli.net/2021/05/17/imntCOz2y8PhHWr.png)

实验使用的数据更大，四个指标稍微提高

消融实验

![截屏2021-05-17 上午11.50.51](https://i.loli.net/2021/05/17/bN45hrLHm3jyGJ7.png)

比较知识表征和文本表征



![截屏2021-05-17 上午11.50.43](https://i.loli.net/2021/05/17/ZflWjGRs4KrDyUc.png)

去除各种联合注意力网络对于AUC有所影响，其它影响不大





![截屏2021-05-17 上午11.50.59](https://i.loli.net/2021/05/17/j23mJopX8Tw71qs.png)



KGAT，它利用KRED[19]中提出的知识图注意网络，从新闻中的实体及其知识图上的邻居中学习基于知识的新闻表示

我们通过比较KIM与其变体(分别从实体中建模用户新闻和候选新闻)来评估knowledge co-encoder 的有效性。





## Case study

![截屏2021-05-17 上午11.59.36](https://i.loli.net/2021/05/17/d3kwSQu8qTnhNBx.png)



通过与LSTUR和KRED的比较，我们进行了一个案例研究来显示KIM的有效性



# 总结

模型性能相比一般的神经推荐方法有所提升，能跑赢结合知识图谱的方法，但没有和基于GCN的方法对比，实质上模型用了很多GCN的部分。模型本质上是一个联合编码器在各个方面的套用，搞得十分复杂，但性能提升一般。

