# Capsule

## 物体姿态

为了正确的分类和识别物体，保持物体部分之间的分层姿态 (hierarchical pose) 关系是很重要的。姿态主要包括平移 (translation)、旋转 (rotation) 和放缩 (scale) 三种形式。

以人为例，在创建图形时，我们首先会定义脸和身体相对于人的位置，更进一层，我们会定义眼睛和嘴巴对于相对于脸的位置，但不是相对于人的位置。因为之前已经有了脸相对于人的位置，现在又有了眼睛相对于脸的位置，那么也有了眼睛相对于人的位置。本质上，你将有层次的创建一个完整的人，而所需要的数学工具就是姿态矩阵 (pose matrix)，这个矩阵定义所有对象表示了部件与整体之间的关系。

Hinton 认为，为了正确地进行分类和对象识别，重要的是保持对象部分之间的分层姿态关系，Capsule 就符合这个重要直觉，它结合了对象之间的相对关系，并以姿态矩阵来表示。

2 维平面中姿态矩阵平移、旋转和放缩物体

![截屏2020-11-07 下午8.42.47](https://i.loli.net/2020/11/07/uWojPBeqEn2RF7c.png)



具体案例：

![截屏2020-11-07 下午8.43.54](https://i.loli.net/2020/11/07/JTfg3L8prPxSRXV.png)

整体是由它的各个部分组成的，如上图：

- 人 (整体) 是由脸和身体组成
- 脸 (整体) 是由眼睛和嘴巴组成
- 身体 (整体) 是由躯干和手组成

每个部分通过一个姿态矩阵与其主体相关联。如果 M 是脸对人姿态矩阵，N 是嘴巴对脸姿态矩阵，那么嘴巴对人的姿态矩阵为 N' = MN。

现在我们有一个照相机，并且我们知道人对相机的帧的姿态矩阵是 P，可以通过连乘姿态矩阵来提取人的每个部分的所有基本属性，比如：

- 脸对相机的帧的姿态矩阵由 M' = PM 给出
- 嘴对相机的帧的姿态矩阵由 N' = M'N = PMN 给出

![截屏2020-11-07 下午8.45.54](https://i.loli.net/2020/11/07/T9MhDxJm8R2jga5.png)

姿态矩阵 P 表示我们可以从相机看对象的不同视点。一张脸上所有特征都是一样的，不同的是你看脸的角度。所有其他对象 (比如身体、嘴巴和手) 的所有视点都可以由 P 得到。

现在知道左眼的位置或嘴的位置就可以推测脸的位置。

其中

- Ev 是眼睛的位置向量

- E 是眼睛对脸的姿态矩阵

- Mv 是嘴巴的位置向量

- M 是嘴巴对脸的姿态矩阵

  

若二者推测的位置一致，则EvE = MvM

## 胶囊

胶囊应该有两个层次，一个是包含多个神经元的胶囊，取代了神经元的位置，另一个是胶囊层，由诸多胶囊组成，类似于卷积层。

胶囊 (Capsule) 是一个包含多个神经元的载体，每个神经元表示了图像中出现的特定实体的各种属性。这些属性可以包括许多不同类型的实例化参数 (instantiation parameter)，例如姿态 (位置、大小、方向)，变形，速度，色相，纹理等。胶囊里一个非常特殊的属性是图像中某个类别的实例的存在。它的输出数值大小就是实体存在的概率。

向量是一个有方向和长度的概念，把胶囊类比于数学向量：

- 长度代表眼睛在图像某个位置存在的概率
- 方向代表眼睛的一些参数，比如位置，转角，清晰度等等

将 Capsule 称作向量神经元 (vector neuron, VN)【只是博客说法】、，而普通的人工神经元叫做标量神经元 (scalar neuron, SN)：

1⃣️矩阵运算转化

【此处符号表示得不好，最好是上一层用v，下一层用u】

假设上一层的低层特征为眼睛、鼻子、嘴巴，对应u1、u2、u3

下一层的uj表示脸，还有其他高层特征

![截屏2020-11-07 下午8.59.39](https://i.loli.net/2020/11/07/Kki8ZSFCNzrjmsJ.png)

此处三个向量的位置是一致的话【向量角度考虑相似】则可以肯定出现在这个地方的是一张脸

2⃣️输入加权求和

高层特征乘以权重

从高层面解释动态路由：

![截屏2020-11-07 下午9.10.55](https://i.loli.net/2020/11/07/vNiK89Cm7Jfrc6E.png)

低层的VNi需要决定被发送到哪个更高级别的VNj，即VN1或VN2，通过耦合参数c来决定

胶囊层是全连接的，每个高级VN都能收到其他低级的所有输入：

- 红点聚集在一起，意味着低级别 VN 的预测彼此接近
- 蓝点聚集在一起，意味着低级别 VN 的预测相差很远

以加粗的VNi为例：

- VNi 的输出远离高级别 VN1 中的“正确”预测的红色簇
- VNi 的输出靠近高级别 VN2 中的“正确”预测的红色簇

动态路由的结果就是调整权重cij，即调整VNi对应高层VN的权重，此处为调高其基于VN2的权重，调低其基于VN1的权重。

 cij的性质：

1. 每个权重是一个非负值
2. 对于每个低级别 VNi，所有权重 cij 的总和等于 1
3. 对于每个低级别 VNi，权重的个数等于高级别 VN 的数量
4. 权重由迭代动态路由 (iterative dynamic routing) 算法确定

动态路由迭代3次，

首先初始化所有b使得c均匀分布（开始是不确定哪个低层特征需要传送到高层，随机初始化肯定不可信，若1/VN数量，和0是一样的）

softmax产出非负数使得总数为1，c成为概率变量。

sj可以视作聚类中心，是低层VN的共识输出

为了使得长度表示概率进行压缩为v，但方向不变

最后用uj|i和vj的点积和bij之和更新bij，bij是低层单个胶囊对高层的预测，点积是所有胶囊对高层的共识预测。

- 当两者相似，点积就大，bij 就变大，低层 VNi 连接高层 VNj 的可能性就变大
- 当两者相异，点积就小，bij 就变小，低层 VNi 连接高层 VNj 的可能性就变小



点积的结果只有三种：正、负、0

![截屏2020-11-07 下午9.45.04](https://i.loli.net/2020/11/07/WkBgbJLVxMZ5u21.png)



点积值越大，参数变化越大

![截屏2020-11-07 下午9.46.56](https://i.loli.net/2020/11/07/Ir5GRc1onWf2z3H.png)

3⃣️非线性激活

压缩高层VN的长度不超过1，而且方向不变。



## 帆船房子二分类的案例

假设低层特征为三角形和长方形，高层特征为帆船和房子

正向作图和反向作图：

![截屏2020-11-07 下午9.55.14](https://i.loli.net/2020/11/07/clHiVeXz2fFjv6A.png)



计算机作图 (computer graphics) ，通常认为是正向作图，是根据各个物体的参数，比如中心横坐标 x，中心纵坐标 y 和旋转角度，在屏幕中打出 (rendering) 帆船的图像。

而反向作图 (inverse graphics) 是根据屏幕中帆船的图像，反推出各个物体的参数。

![截屏2020-11-07 下午9.56.16](https://i.loli.net/2020/11/07/neXzD9h2FvNQIEx.png)

胶囊网络就是反向作图。

假设**蓝箭头**代表**三角形**，**黑箭头**代表**长方形**：

- 蓝箭头的长度表示三角形出现的概率大小
- 黑箭头的长度表示长方形出现的概率大小
- 蓝箭头的方向表示三角形的姿态参数 (这里指朝向)
- 黑箭头的方向表示长方形的姿态参数 (这里指朝向)

![截屏2020-11-07 下午9.57.14](https://i.loli.net/2020/11/07/JPIarg3AMsLxYKo.png)

- 有一个蓝箭头和一个黑箭头非常大，说明在上图右边各自相应位置上存在的三角形和长方形的可能性非常大
- 其他地方的所有蓝箭头和黑箭头非常小，说明在上图右边那些位置上存在的三角形和长方形的可能性非常小
- 根据蓝箭头的方向，我们大概知道三角形逆时针转了 65 度
- 根据黑箭头的方向，我们大概知道长方形顺时针转了 16 度

同理根据三角形和长方形也能识别出房子，也能知道其旋转角度。

**capsule实现的equivariance实现不仅识别帆船，还能看出不同帆船的倾斜角度。**



通过动态路由，找到低层VN最有可能贡献给哪个高层VN，即在实例中，找到哪个三角形和长方形组合成房子或帆船。



用i表示低层，j表示高层：【由矩阵运算而来的i此处忽略了一层特征变换】

- bij = 低层 VNi 连接高层 VNj 的可能性，初始值为 0
- cij = 低层 VNi 连接高层 VNj 的概率，总和为 1
- bi = 低层 VNi 连接所有高层 VNj 的可能性，初始值为 0
- ci = 低层 VNi 连接所有高层 VNj 的概率
- Uj|i = 由低层 VNi 预测的高层 VNj

cij是 bij做 softmax 之后的结果，因此初始值 0.5 (j 层只有 2 个 VN，那么开始时均分bij是一样的)。

对长方形 (i=1) 和三角形 (i=2)

- 归一：
  - 计算概率 (c11, c12) = 归一(b11, b12)
  - 计算概率 (c21, c22) = 归一(b21, b22)
- 预测：
  - 从长方形到房子 U1|1 和小船 U2|1
  - 从三角形到房子 U1|2 和小船 U2|2
- 加总：
  - 房子的综合预测 s1 = c11U1|1 + c21U1|2
  - 帆船的综合预测 s2 = c12U2|1 + c22U2|2
- 压缩：
  - 单位化房子的综合预测 v1 = 压缩(s1)
  - 单位化帆船的综合预测 v2 = 压缩(s2)
- 更新：
  - b11 = b11 + 相似度(U1|1, v1)
  - b12 = b12 + 相似度(U2|1, v2)
  - b21 = b21 + 相似度(U1|2, v1)
  - b22 = b22 + 相似度(U2|2, v2)



具体过程：



![截屏2020-11-07 下午10.22.23](https://i.loli.net/2020/11/07/C2dbpz7qY59wZli.png)

预测：由primary capsules得到的胶囊输入经过矩阵运算得到高层图形的位置

![截屏2020-11-07 下午10.30.18](https://i.loli.net/2020/11/07/vEFRGLqnIrj1NV9.png)

加总就是分别将房子/帆船的预测位置求个加权总和，可以理解成房子/帆船的**平均位置**，然后压缩

![截屏2020-11-07 下午10.32.03](https://i.loli.net/2020/11/07/xBLMnPIt5imYd4D.png)

压缩向量

更新参数：根据加权和来推测房子/帆船的可能性

最后得到四个概率：

![截屏2020-11-07 下午10.34.05](https://i.loli.net/2020/11/07/3nJcp4U7yK2dtai.png)

- 如果 b11 > b12 则 c11 > c12，那么三角形路由到房子概率大，反之到帆船概率大
- 如果 b21 > b22 则 c21 > c22，那么长方形路由到房子概率大，反之到帆船概率大

## 动态路由



最大池化只有最活跃的神经元会被选择传递到下一层，而这也是层之间有价值的空间信息丢失的原因，动态路由则是较为底层的特征（手、眼睛、嘴巴等）将只被传送到与之匹配的高层【只是相对而言，某些不属于该层高层特征对应的权重极小】

本质是决定低层特征哪些需要传送到高层特征，通过动态地调整权重，结合特征组成不同的分类输出。

每次迭代过程中得到一个聚类中心，与其相近的低层特征的权重会不断增加，相对地越来越靠近聚类中心，最终形成一个类别。

通过计算$$c_i$$来量化一个低层次胶囊与其父胶囊之间的联系.$c_{ij}$表示低层胶囊i激活胶囊j的概率分布

等价于CNN中，经过卷积层再输入池化层降低尺寸，那么最大池化是通过选取最大值，平均池化是求均值，动态路由是决定各自的权重。

高层特征是在底层特征基础上 加权求和得到的，

卷积层是 CNN 的重要组成部分，它会尽可能的去检测出重要的模式，然后逐渐的形成 high level 的 feature，然后将这些 feature 继续编辑成更加 high level 的 feature。然后用 fc layer 输出最终的分类结果。CNN 主要是利用 max pooling 或者 连续的卷积层，来降低数据的尺寸，所以增加了高层神经元的“感受野”，所以，允许他们可以在输入图像上的更大的区域内检测到更高层的feature。Max pooling 是使得 CNN 能够工作的非常好的重要原因。但是也别被其良好的结果所欺骗了。其丢失了有价值的信息。

## 向量表示

讨论胶囊网络时，需从识别物体出发，通过物体之间的分层姿态逐渐识别物体。

计算机作图是根据各个物体的参数组合成不同的图形，而大脑实现的inverse graphics，即根据图形反推各个部分的参数，hinton希望capsule这样做，则胶囊就需要知道特征的姿态信息。

比如，同一物体可以通过姿态变换来实现不同的视觉效果，比如拍照，可以转动相机的角度拍出不同效果，但相机的对象即人的本身姿态或器官的相对位置是不变的。

因此对应的，当相机角度变换时，可以根据姿态矩阵来找到相应的位置。

CNN只根据特征是否存在来识别物体，实现invariance（不变性），表示不随变化而变化，capsule则实现Equivariance（同变性），表示随变化而变化，可以表示分类是否存在，也可以知道特征的姿态关系，这就需要胶囊网络的向量结构。

为了保存特征的姿态信息，采用向量形式。

![image-20201108163530450](https://i.loli.net/2020/11/08/TzgUhG53juy9Yf7.png)

![image-20201108163540290](https://i.loli.net/2020/11/08/EPvghoNdY4CGp2V.png)