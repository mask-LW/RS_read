# 推荐算法常用的评价指标

TP（true positive）：表示样本的真实类别为正，最后预测得到的结果也为正；
FP（false positive）：表示样本的真实类别为负，最后预测得到的结果却为正；
FN（false negative）：表示样本的真实类别为正，最后预测得到的结果却为负；
TN（true negative）：表示样本的真实类别为负，最后预测得到的结果也为负.

# 准确率

准确率表示预测正确的样本数占总样本书的比例。

$Accuracy =  \frac{TP+TN}{TP+TN+FP+FN}$

# 精确率

精确率表示预测为正样本的样本中，正确预测为正样本的概率。
$Precission =  \frac{TP}{TP+FP}$

# 召回率

召回率表示正确预测出正样本占实际正样本的概率。
$Recall =  \frac{TP}{TP+FN}$

# F1 score

折中了召回率与精确率。
 $F1 = \frac{2*Recall*Precision}{Recall+Precision}$

# Mean Reciprocal Rank(MRR)

正确检索结果值在检索结果中的排名来评估检索系统的性能。

系统的性能。

 $MRR = \frac{1}{Q} \sum_{i=1}^{|Q|}\frac{1}{rank_i}$

其中，∣ Q ∣ 是用户的个数，$rank_i$是对于第i个用户，推荐列表中第一个在ground-truth结果中的item所在的排列位置。

![截屏2020-10-21 下午9.47.49](https://i.loli.net/2020/10/21/1QkLzN5wtGHIAb2.png)



# Normalized Discounted Cummulative Gain(NDCG)

**累积增益CG**，推荐系统中CG表示将每个推荐结果相关性的分值累加后作为整个推荐列表的得分：
$CG_k = \sum ^k_{i=1} rel_i$
其中，$rel_i$表示位置i的推荐结果的相关性，k表示推荐列表的大小。

CG没有考虑每个推荐结果处于不同位置对整个推荐结果的影响，例如，我们总是希望相关性大大的结果排在前面，相关性低的排在前面会影响用户体验。

举例：假设搜索“篮球”结果，最理想的结果是：B1、B2、 B3。而出现的结果是 B3、B1、B2的话，CG的值是没有变化的，因此需要下面的DCG。



**DCG**在CG的基础上引入了位置影响因素，让排名越靠前的结果越能影响最后的结果。计算公式如下：


$$
DCG_k = \sum^k_{i=1} \frac{2^{rel_i}-1}{log_2(i+1)}
$$


从上面的式子可以得出：

1）推荐结果的相关性越大，DCG越大。

2）相关性好的排在推荐列表前面的话，推荐效果越好，DCG越大。

DCG针对不同的推荐列表之间很难进行横向评估，而我们评估一个推荐系统不可能仅使用一个用户的推荐列表及相应结果进行评估，而是对整个测试集中的用户及其推荐列表结果进行评估。

那么，不同用户的推荐列表的评估分数就需要进行归一化，也就是**NDCG**。

**IDCG**表示推荐系统某一用户返回的最好推荐结果列表， 即假设返回结果按照相关性排序， 最相关的结果放在最前面， 此序列的DCG为IDCG。

因此DCG的值介于 (0,IDCG] ，故NDCG的值介于(0,1]，那么用户u的NDCG@K定义为：
$$
NDCG_u@k = \frac{DCG_u@k}{IDCG_u}
$$
平均NDCG的值为：
$$
NDCG_u@k = \frac{\sum_{u\in U} DCG_u@k}{IDCG_u}
$$
![4155986-e19e155504234f93](https://i.loli.net/2020/10/21/rlmpbwSFk59ZjKI.png)

CG的计算结果为3+1+2+3+2 = 11。DCG的值为6.69。理想状况下，我们的IDCG排序结果的相关性应该是3，3，2，2，1，因此IDCG为7.14(具体过程不再给出)，因此NDCG结果为6.69/7.14 = 0.94。

# ROC与AUC

ROC曲线的横轴为**假正例率FPR(越小越好)**，纵轴为**真正例率TPR(越大越好)**。
$ FPR = \frac{FP}{TN+FP}$  样本为假但预测为真/所有为假的样本（真阳率）
$$ TPR = \frac{TP}{TP+TN}$$   样本为真且预测为真/所有为真的样本）（假阳率）

ROC计算过程：

1)首先每个样本都需要有一个label值，并且还需要一个预测的score值（取值0到1）;

2)然后按这个score对样本由大到小进行排序，假设这些数据位于表格中的一列，从上到下依次降序;

3)现在从上到下按照样本点的取值进行划分，位于分界点上面的我们把它归为预测为正样本，位于分界点下面的归为负样本;

4)分别计算出此时的TPR和FPR，然后在图中绘制（FPR, TPR）点。

ROC(Receiver Operating Characteristic curve)接受者操作特征曲线。

上面我们都只是把从一组预测样本得到的[FPR,TPR]作为一个点描述，并且我们知道阈值的改变会严重影响FPR和TPR，那么，如果我们把所有可能的阈值都尝试一遍，再把样本集预测结果计算得到的所有[FPR,TPR]点都画在坐标上，就会得到一个曲线：

![截屏2020-10-22 上午10.32.31](https://i.loli.net/2020/10/22/FMjNzmrkcxCTW85.png)



- 横竖都不是阈值坐标轴，这里没有显示阈值。
- 蓝色线更加靠近左上角，比红色线更好



AUC，Area under the Curve of ROC (AUC ROC)，就是ROC曲线下面的面积。如上图，蓝色曲线下面的面积更大，也就是它的AUC更大。

AUC的含义：测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score。或者，任意给定一个负样本，所有正样本的score中有多大比例是大于该负类样本的score

![截屏2020-10-22 上午10.34.15](https://i.loli.net/2020/10/22/QSLM6A8JUGfchan.png)



AUC面积越大，算法越好。

当我们写好算法之后，可以用一个测试集来让这个算法进行分类预测，然后我们绘制ROC曲线，观察AUC面积，计算ACC精度，用这些来对算法的好坏进行简单评估。

![截屏2020-10-22 上午10.37.54](https://i.loli.net/2020/10/22/Vt5bZAv4UswERYP.png)



# P-value

硬币有正反两面，在概率中我们知道，出现正反面的概率各为50%（1/2），所以作为一个正常的硬币，如果我们投无限次后，结果一定会是正反各占50%。但是，如果我想知道自己手中的硬币，到底是不是正常的硬币，有没有做过手脚，在实际操作中是没办法投掷无限次的。因此，我们只能用有限的结果来判断“硬币是否为常规硬币”这个问题的答案。

在统计学上，做这个检验时，通常会设定一个虚无假设（也叫零假设，Null Hypothesis），通常记作H0。以及一个对立假设（Alternative Hypothesis），及与虚无假设对立的假设，如果证明虚无假设错误，则可以推出对立假设成立。

在掷硬币这个例子中，我们可以设定

H0: 手中的硬币是常规硬币

H1: 手中的硬币做过手脚

如果手中硬币是常规硬币，我们知道正面和反面出现的概率各为50%，所以如果我投掷10次硬币，则正面和反面出现的次数各位5次。正面5次，反面5次，就是我们对于投掷10次硬币的期望值（expected value）。

现在我们开始投掷硬币，出现的是正面3次，反面7次。这个结果就是我们对于投掷10次硬币的观测值（observed valued），即实际的结果。

通过分析期望值和观测值的差距，我们就可以判断出硬币是否正常。而这个期望值和观测值差距的判断方法就是chi-square。

![截屏2020-10-22 上午10.13.19](https://i.loli.net/2020/10/22/htIN6FOC8dr5vEL.png)

上图即为chi-square的计算公式，O代表观测值（observed value），E代表期望值（expected value）。有没有觉得这和方差的公式很像？没错，其实方差是一组数据与其均值的比较，而chi-suaqre是一组数据与另一组数据期望值的比较。

那么在掷硬币这个例子中chi-square（卡方）=(3-5)^2/5+(7-5)^2/5=1.6

![截屏2020-10-22 上午10.14.30](/Users/mac/Library/Application Support/typora-user-images/截屏2020-10-22 上午10.14.30.png)

上图即为卡方分布表，左上角的α表示错误拒绝H0假设的概率（即虚无假设事实上成立，但我们计算出的结果却错误判断虚无假设不成立的概率）。n代表自由度（degree of freedom），即独立变量数减1，在这个例子中，独立变量数为2（正面和反面），所以自由度为1（2-1=1）。

![截屏2020-10-22 上午10.16.34](https://i.loli.net/2020/10/22/4OF2hZCPs8y69u1.png)

与上图不一样的卡方分布图，比如Figure 3。P代表α，即P(当H0为真时拒绝H0)（其实就是p-value），df代表自由度（degree of freedom）。

假设置信度为95%，即错误拒绝H0的概率为0.05。展开解释就是，我们有95%的概率确信检验结果正确，有5%的概率会错误拒绝虚无假设。（我们总说的p值与0.05比较就是这个啦，其实不一定时0.05，根据具体情况可以设置不一样的值，只是大部分时候都用0.05）

对照着卡方分布表（Figure 3），找到1所在的行（我们计算出的chi-square自由度是1），发现1.6是介于1.323和2.706之间，查表得出其p值为0.25到0.1之间，大于0.05，所以我们不能拒绝H0。换句话说，H0成立，即硬币是常规硬币，没有做手脚。

总结一下，

p-value的作用：p-value就是用来判断H0假设是否成立的依据。因为期望值是基于H0假设得出的，如果观测值与期望值越一致，则说明检验现象与零假设越接近，则越没有理由拒绝零假设。如果观测值与期望值越偏离，说明零假设越站不住脚，则越有理由拒绝零假设，从而推出对立假设的成立。

大部分时候，我们假设错误拒绝H0的概率为0.05，所以如果p值小于0.05，说明错误拒绝H0的概率很低，则我们有理由相信H0本身就是错误的，而非检验错误导致。大部分时候p-value用于检验独立变量与输入变量的关系，H0假设通常为假设两者没有关系，所以若p值小于0.05，则可以推翻H0（两者没有关系），推出H1（两者有关系）。

p value: 把H0错判为假的概率。p越小说明，错判概率越小，则有足够把握拒绝H0,接受H1

